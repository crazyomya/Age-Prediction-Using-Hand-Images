{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6db58c",
   "metadata": {},
   "source": [
    "# LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8cb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2 \n",
    "import os\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b9fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6235b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to create data set\n",
    "def create_dataset(old_path, young_path, adult_path):\n",
    "    \n",
    "    # list to store extracted features of an image\n",
    "    features = []\n",
    "    \n",
    "    # list to store class label, 1 for live, 0 for spoof\n",
    "    labels = []    \n",
    "    \n",
    "    radius = 3\n",
    "    \n",
    "    # number of neighbors to consider for LBP\n",
    "    n_points = 8 * radius \n",
    "    \n",
    "    # sampling type for LBP\n",
    "    METHOD = 'uniform'       \n",
    "    \n",
    "    path_array = [old_path, young_path, adult_path]\n",
    "    \n",
    "    for path in path_array:\n",
    "        \n",
    "        # storing all images in a folder in a list 'files'\n",
    "        files = os.listdir(path) \n",
    "        \n",
    "        # loop through the images in the folder\n",
    "        for img in files:\n",
    "            \n",
    "            \n",
    "            # reading the image in grayscale using cv2\n",
    "            image = cv2.imread(os.path.join(path + img), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            \n",
    "            # resizing the image so all images are of same size\n",
    "            \n",
    "            resized_img = cv2.resize(image, (300, 300))\n",
    "            \n",
    "            # Extracting features of an image using LBP\n",
    "               \n",
    "            lbp = local_binary_pattern(resized_img, n_points, radius, METHOD)\n",
    "                \n",
    "                 # Converting into 1-D array\n",
    "            fd=lbp.flatten()\n",
    "                \n",
    "            \n",
    "                \n",
    "                # label 1 for adult images, 0 for YOung images, 2 for old\n",
    "            class_identifier = 1\n",
    "            if 'Young' in path:\n",
    "                class_identifier = 0\n",
    "            elif 'Old' in path:\n",
    "                class_identifier = 2\n",
    "                \n",
    "             # appending exracted features to the list\n",
    "            features.append(fd) \n",
    "            \n",
    "            #adding corresponding class label to the list\n",
    "            labels.append(class_identifier)  \n",
    "                      \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565e6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for differet folders\n",
    "training_old_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Train\\\\Old\\\\\"\n",
    "training_young_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Train\\\\Young\\\\\"\n",
    "training_adult_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Train\\\\Adult\\\\\"\n",
    "testing_old_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Test\\\\Old\\\\\"\n",
    "testing_young_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Test\\\\Young\\\\\"\n",
    "testing_adult_path = \"D:\\\\College\\\\Third Year\\\\Computer Vision\\\\cp2\\\\Datasets\\\\Common Dataset\\\\Test\\\\Adult\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e725535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data captured\n",
      "testing data captured\n"
     ]
    }
   ],
   "source": [
    "# LBP \n",
    "# Training and testing datasets\n",
    "\n",
    "x_train_data,y_train = create_dataset(training_old_path, training_young_path, training_adult_path)\n",
    "\n",
    "print('training data captured')\n",
    "\n",
    "x_test,y_test = create_dataset(testing_old_path,testing_young_path, testing_adult_path)\n",
    "print('testing data captured')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a090d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model\n",
    "\n",
    "lbp_clf = svm.SVC()\n",
    "lbp_clf.fit(x_train_data,y_train)\n",
    "\n",
    "# Predict on the test features, print the results\n",
    "\n",
    "lbp_y_pred = lbp_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09ceaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  \t\t0.7055961070559611\n",
      "Balanced accuracy: \t 0.36604372566636717\n",
      "Precision accuracy: \t 0.6251082251082251\n",
      "Recall Score: \t\t 0.7055961070559611\n",
      "F1 Score: \t\t 0.7055961070559611\n",
      "\n",
      "Confusion Matrix: \n",
      " [[564   0  36]\n",
      " [149  10   0]\n",
      " [ 57   0   6]]\n"
     ]
    }
   ],
   "source": [
    "#SVM Linear\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, lbp_y_pred)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, lbp_y_pred))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, lbp_y_pred,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, lbp_y_pred,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, lbp_y_pred,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, lbp_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed7d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  70.07299270072993 %\n",
      "Train Accuracy: 0.9827956989247312\n",
      "Test Accuracy: 0.7007299270072993\n",
      "Accuracy:  \t\t0.7007299270072993\n",
      "Balanced accuracy: \t 0.6404312668463611\n",
      "Precision accuracy: \t 0.5766448611741294\n",
      "Recall Score: \t\t 0.7007299270072993\n",
      "F1 Score: \t\t 0.7007299270072993\n",
      "\n",
      "Confusion Matrix: \n",
      " [[480  92  28]\n",
      " [112  42   5]\n",
      " [  6   3  54]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier(max_depth=13)\n",
    "model_dt.fit(x_train_data, y_train)\n",
    "joblib.dump(model_dt,\"model_dt\")\n",
    "\n",
    "#predicting the traget variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred1)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred1))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred1,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred1,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred1,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d126a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.8090024330900243\n",
      "Accuracy:  \t\t0.8090024330900243\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'balanced_accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27436\\2935335286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:  \\t\\t\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Balanced accuracy: \\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision accuracy: \\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall Score: \\t\\t\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'balanced_accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "model_rf.fit(x_train_data, y_train)\n",
    "joblib.dump(model_rf,\"model_rf\")\n",
    "\n",
    "y_pred2 = model_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",model_rf.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_rf.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred2)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred2))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred2,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred2,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred2,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf9e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8311827956989247\n",
      "Test Accuracy: 0.5693430656934306\n",
      "Accuracy:  \t\t0.5693430656934306\n",
      "Balanced accuracy: \t 0.44126235399820307\n",
      "Precision accuracy: \t 0.34888135981261903\n",
      "Recall Score: \t\t 0.5693430656934306\n",
      "F1 Score: \t\t 0.5693430656934306\n",
      "\n",
      "Confusion Matrix: \n",
      " [[425  64 111]\n",
      " [151   7   1]\n",
      " [ 27   0  36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "model_knn.fit(x_train_data, y_train)\n",
    "#joblib.dump(model_knn,\"model_knn\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred3)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred3))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred3,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred3,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred3,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f3323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.7944038929440389\n",
      "Accuracy:  \t\t0.7944038929440389\n",
      "Balanced accuracy: \t 0.6985050414295698\n",
      "Precision accuracy: \t 0.7368970592367785\n",
      "Recall Score: \t\t 0.7944038929440389\n",
      "F1 Score: \t\t 0.7944038929440389\n",
      "\n",
      "Confusion Matrix: \n",
      " [[545  44  11]\n",
      " [104  55   0]\n",
      " [ 10   0  53]]\n"
     ]
    }
   ],
   "source": [
    "#xgboost classifier\n",
    "model_xgboost = XGBClassifier().fit(x_train_data, y_train)\n",
    "joblib.dump(model_xgboost,\"model_xgboost\")\n",
    "y_pred5 = model_xgboost.predict(x_test)\n",
    "print(\"XGboost\")\n",
    "print(\"Train Accuracy:\",model_xgboost.score(x_train_data, y_train))\n",
    "print(\"Test Accuracy:\",model_xgboost.score(x_test, y_test))\n",
    "print(\"Accuracy:  \\t\\t\"+str(accuracy_score(y_test, y_pred5)))\n",
    "print('Balanced accuracy: \\t', balanced_accuracy_score(y_test, y_pred5))\n",
    "print('Precision accuracy: \\t', precision_score(y_test, y_pred5,average='macro'))\n",
    "print(\"Recall Score: \\t\\t\",metrics.recall_score(y_test, y_pred5,average='weighted'))\n",
    "print(\"F1 Score: \\t\\t\",metrics.f1_score(y_test, y_pred5,average='micro'))\n",
    "print('\\nConfusion Matrix: \\n',confusion_matrix(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12583ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
